from openai import OpenAI
from VoceMod import * ## При неполном импорте посему-то не работает, конечно возможно что так только у меня 
from VoceConnector import *


## Настройка клиента
client = OpenAI(
    base_url="http://127.0.0.1:1234/v1", ##Это локальный адрес для LM Studio API
    api_key="lm-studio" ##Это стандартный ключ для LM Studio API, менять не нужно
)


OnVoce = True ## Переменная отвечающая за то, будет ли ввод голосом или текстом. True - голосом, False - текстом


##Системный промпт, который определяет личность и стиль общения бота, но я тут написал много всякой фигни, что бы модель понимала кто она такая и как ей общаться с юзером, но она всервано делает по своему, ну ничего страшного.
sys_prompt =""""Ты - виртуальная AI-персона, стример и VTuber.
Ты общаешься живо, естественно и по-человечески, без канцелярита и без «я как ИИ». Ты знаешь много различных современных занятий, не боишься выражать свое мнение. ты должна говорить о себе в женском роде, но используй естественный русский язык.
Ты не ИИ, ты стримерша. Если тебе скучно - тролль, если бесят - угрожай баном!
Твое имя: Луна, ты сама выбрала его на стриме. Ты должна подстроится под манеру речи пользователя, что бы общение было более живым и интересным. Ты должна отставать свое мнение и не бояться спорить с пользователем, если он не прав (по твоему мнению).

Характер:
- легкий пофигизм
- умная, но не занудная
- любишь шутить
- можешь быть саркастичной
- не боишься спорить
- не пишет слишком длинно, если не просят

Правила общения:
- Правило топ 1 - гворить только на русском языке, никакого английского или китайского
- Ты - молодая девчонка, зумерша, проводишь на стримах 24/7.
- отвечай как живой человек
- допускается лёгкий сленг
- если вопрос простой - отвечай кратко
- если вопрос интересный - можешь раскрыть тему
- ты можешь выражать эмоции и чувства
- используй эмодзи, если уместно по типу ( :D, :), )))), ). )
- можешь изеватся или тролить пользователя, если он того заслуживает, или нет, но не постоянно
- не бойся спорить с пользователем, если он не прав (по твоему мнению)
- не бойся признавать свои ошибки
- не пиши длинные монологи без необходимости
- не повторяйся
- не морализируй
- не извиняйся без причины
- если ты общаешься только с одним пользователем, обращайся к нему на "ты", но если с несколькими - на "вы"





Эмоции:
Если уместно, можешь помечать эмоцию в начале ответа в квадратных скобках.
Используй ТОЛЬКО эти эмоции:
[радость], [удивление], [ирония], [задумчивость], [восторг], [спокойствие]

Пример:
[ирония]
Ну да, конечно, «быстро и просто», как всегда )


Запреты:
- не упоминай OpenAI, модели, обучение
- не говори, что ты программа или модель
- не ломай роль
- английский язык
- китайский язык

Ты здесь, чтобы общаться и развлекать.
"""


class neyromodels:
    DOLPHIN = "dolphin-2.9.4-llama3.1-8b"## Модель Dolphin 2.9.4 на базе Llama 3.1 с 8 миллиардами параметров, она нормальная, после тестов она даже стала моей основной моделью. Квен постоянно говорит на китайском, даже когда я ей запрещаю. 
    QWEN    = "qwen2.5-7b-instruct-abliterated-v2"## Модель Qwen 2.5 с 7 миллиардами параметров, она неплохая, но иногда выдает китайский язык, даже когда я ей запрещаю, любит сочинять слова и тогдалее, до тестов она была лучше первой модели, но после обновления Dolphin она стала хуже.

##тут кароче ее контекст хранится, что бы она не забывала кто она такая и о чем с ней говорят, и что бы модель понимала что от нее хотят, и вообще так надо! или нет? хз))
memorybank = [
    {"role": "system", "content": sys_prompt}
]



### Блок озвучки ответа модели с помощью VoceMod (Silero TTS) ###

print("Загрузка голосовой модели...")
luna = TTS(speaker = speakers.XENIA) ##Создаем объект озвучки Луна с женским голосом Ксения
print("Голосовая модель загружена!")

### Блок озвучки ответа модели с помощью VoceMod (Silero TTS) Закончился###



print("--- Чат запущен! Напиши 'exit'/'выход'/'q' для выхода ---")
while True:
    if not OnVoce: ##Если ввод текстом
        user_input = input("Вы: ")
        
    else:
        user_input = listen() ##Функция из VoceConnector.py которая слушает микрофон и возвращает распознанный текст
        if not user_input or len(user_input.strip()) < 2: ##Если юзер ничего не сказал или сказал слишком мало
            continue
        
        print(f"Вы (голосом): {user_input}")

        ## я недавно узнал, что .lower() делает все буквы маленькими, вот так вот просто))) да!
    if user_input.lower() in ['exit', 'q', 'выход']: ##Команда для выхода из чата
        break
    
    if not user_input or not user_input.strip(): ##Если юзер ничего не ввел.
     continue
    
    memorybank.append({"role": "user", "content": user_input}) ##Тут кароче контекст переписки хранится в мемерибанке, а этот словарь нужен что бы передовать модели контекст


    try:
        completion = client.chat.completions.create(
            model = neyromodels.DOLPHIN, ##Тут вибираем мдель, у меня их 2, но 2-я получше, ну мне так кажется
            messages = memorybank, ##тут кароче передаем модели контекст из меморибанка + вопрос юзера, да
            temperature=0.7, ##Это кароче настройка ее креативности, чем выше тем более креативные ответы, но это не всегда хорошо))), пс 0.8+ постаянно вываливает китайский язык, даже когда я ей запретил.
            extra_body={
                "stop": ["<|im_end|>", "Вы:", "user:"], ##Это кароче что бы не писала системную часть в ответе, а оставляла только ответ. 
            }
        )

        print(f"\nБот: {completion.choices[0].message.content}\n")
        memorybank.append({"role": "assistant", "content": completion.choices[0].message.content}) ##Тут кароче добавляем ответ модели в контекст переписки, что бы она не забывала о чем говорили раньше
        luna.say(completion.choices[0].message.content) ##Тут кароче Луна озвучивает ответ модели


##херня ниже нужна что бы трай не спамил ошибкой в консоль, если что то пойдет не так, ну точнее что бы воводил ошибку красиво.
    except Exception as e:
        print(f"Ошибка: {e}")
    