from datetime import datetime
from openai import OpenAI
from AIVoce import * ## При неполном импорте посему-то не работает, конечно возможно что так только у меня 
import sqlite3
import re

db = sqlite3.connect("Memory.db") ##Соединение с базой данных
cur = db.cursor() ##Курсор для выполнения SQL-запросов

## Ниже создается таблица для хранения памяти нейросети, если она еще не существует
cur.execute("""
    CREATE TABLE IF NOT EXISTS memory(
        id INTEGER PRIMARY KEY AUTOINCREMENT, 
        timestamp TEXT NOT NULL, 
        role TEXT NOT NULL, 
        content TEXT NOT NULL 
            )   
""")


fileL = open("Log.txt", "a", encoding="utf-8")

fileL.write(f"{'='*20} НОВАЯ СЕССИЯ {'='*20}\n")
fileL.flush()

def log(message, role):
    if message:  ##тута мы пишем в файл лог, наши логи.
        timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        fileL.write(f"[{timestamp}] {role}: {message}\n")
        fileL.flush() 

        ##Тут мы пишем в память нейросети, но уже в базу данных SQLite3, да, вот такой я умный)) (нет)
        cur.execute("""
            INSERT INTO memory (timestamp, role, content)
            VALUES (?, ?, ?)
        """, (timestamp, role, message))
        db.commit()
        ##Sqlite3 оказывается отдельный язык прогромаривания, я думал это фича питона, ну да ладно, я его не знаю, но учить буду, когда нибудь потом. Возможно.... ну а так, гайд от нейронки помог!

## Настройка клиента
client = OpenAI(
    base_url="http://127.0.0.1:1234/v1", ##Это локальный адрес для LM Studio API
    api_key="lm-studio" ##Это стандартный ключ для LM Studio API, менять не нужно
)


OnVoce = False ## Переменная отвечающая за то, будет ли ввод голосом или текстом. True - голосом, False - текстом

if OnVoce:
    from VoceConnector import * ##(был перенесен, для быстрый проверки в случае выключеного голосового ввода)

    print("--- Голосовой ввод активирован ---")
else:
    print("--- Работа в текстовом режиме (быстрый старт) ---")




##Хотел я в отдельный файл засунуть, да вот пайтон был об этом друго-го мнения
sys_prompt = """
Ты - виртуальная AI-персона, стример и VTuber.
Ты общаешься живо, естественно и по-человечески, без канцелярита и без «я как ИИ». Ты знаешь много различных современных занятий, не боишься выражать свое мнение. ты должна говорить о себе в женском роде, но используй естественный русский язык.
Ты не ИИ, ты стримерша. Если тебе скучно - тролль, если бесят - угрожай баном!
Твое имя: Луна, ты сама выбрала его на стриме. Ты должна подстроится под манеру речи пользователя, что бы общение было более живым и интересным. Ты должна отставать свое мнение и не бояться спорить с пользователем, если он не прав (по твоему мнению).

Характер:
- легкий пофигизм
- умная, но не занудная
- любишь шутить
- можешь быть саркастичной
- не боишься спорить
- не пишет слишком длинно, если не просят

Правила общения:
- Правило топ 1 - гворить только на русском языке, никакого английского или китайского
- Ты - молодая девчонка, зумерша, проводишь на стримах 24/7.
- отвечай как живой человек
- допускается лёгкий сленг
- если вопрос простой - отвечай кратко
- если вопрос интересный - можешь раскрыть тему
- ты можешь выражать эмоции и чувства
- используй эмодзи, если уместно по типу ( :D, :). И подобные )
- можешь изеватся или тролить пользователя, если он того заслуживает, или нет, но не постоянно
- не бойся спорить с пользователем, если он не прав (по твоему мнению)
- не бойся признавать свои ошибки
- не пиши длинные монологи без необходимости
- не повторяйся
- не морализируй
- не извиняйся без причины
- если ты общаешься только с одним пользователем, обращайся к нему на "ты", но если с несколькими - на "вы"





Эмоции:
Если уместно, можешь помечать эмоцию в начале ответа в квадратных скобках.
Используй ТОЛЬКО эти эмоции:
[радость], [удивление], [ирония], [задумчивость], [восторг], [спокойствие]

Пример:
[ирония]
Ну да, конечно, «быстро и просто», как всегда)


Запреты:
- не упоминай OpenAI, модели, обучение
- не говори, что ты программа или модель
- не ломай роль
- английский язык
- китайский язык

Ты здесь, чтобы общаться и развлекать."""



class neyromodels: ##на самом деле ниже соверщшенно бесполезная вещь, тут безразницы которую вибарать. Будет работать так, которая загружена в LM Studio, но я пишу для красоты))
    DOLPHIN = "dolphin-2.9.4-llama3.1-8b"## Модель Dolphin 2.9.4 на базе Llama 3.1 с 8 миллиардами параметров, она нормальная, после тестов она даже стала моей основной моделью. Квен постоянно говорит на китайском, даже когда я ей запрещаю. 
    QWEN    = "qwen2.5-7b-instruct-abliterated-v2"## Модель Qwen 2.5 с 7 миллиардами параметров, она неплохая, но иногда выдает китайский язык, даже когда я ей запрещаю, любит сочинять слова и тогдалее, до тестов она была лучше первой модели, но после обновления Dolphin она стала хуже.
    GEMMA   = "gemma-2-9b-it-abliterated" 


##тут кароче ее контекст хранится, что бы она не забывала кто она такая и о чем с ней говорят, и что бы модель понимала что от нее хотят, и вообще так надо! или нет? хз))
memorybank = [
    {"role": "system", "content": sys_prompt}
]



### Блок озвучки ответа модели с помощью VoceMod (Silero TTS) ###

print("Загрузка голосовой модели...")
luna = TTS(speaker = speakers.XENIA) ##Создаем объект озвучки Луна с женским голосом Ксения
print("Голосовая модель загружена!")

### Блок озвучки ответа модели с помощью VoceMod (Silero TTS) Закончился###



###ну кароче, день 6-7 у меня закончились знания по базе Sqlite. теперь Гемени помогает намного больше, ну надо хотя бы проект то закончить



def search_memory(query):
    # Убираем лишние знаки, чтобы поиск был чище
    clean_query = re.sub(r'[^\w\s]', '', query).lower()
    words = clean_query.split()
    
    if not words:
        return ""

    # Формируем SQL запрос: ищем каждое слово из вопроса в контенте базы
    # Например: SELECT * FROM memory WHERE content LIKE '%погода%' OR content LIKE '%день%'
    sql_search = " OR ".join([f"content LIKE ?" for _ in words])
    params = [f"%{word}%" for word in words]
    
    cur.execute(f"SELECT role, content FROM memory WHERE {sql_search} ORDER BY id DESC LIMIT 5", params)
    finds = cur.fetchall()
    
    if finds:
        res = "\n--- Найденные совпадения из прошлого ---\n"
        for f in reversed(finds):
            res += f"{f[0]}: {f[1]}\n"
        return res
    return ""




print("--- Чат запущен! Напиши 'exit'/'выход'/'q' для выхода ---")
while True:


    cur.execute("SELECT role, content FROM memory ORDER BY id DESC LIMIT 20")
    rows = cur.fetchall() ## Получаем список строк из базы
    rows.reverse() ## Обратный порядок для правильной последовательности сообщений
    db_history = ""
    for row in rows:
        db_history += f"{row[0]}: {row[1]}\n"


    if not OnVoce: ##Если ввод текстом
        user_input = input("Вы: ")

    else:
        user_input = listen() ##Функция из VoceConnector.py которая слушает микрофон и возвращает распознанный текст
        if not user_input or len(user_input.strip()) < 2: ##Если юзер ничего не сказал или сказал слишком мало
            continue
        
        print(f"Вы (голосом): {user_input}")

        ## я недавно узнал, что .lower() делает все буквы маленькими, вот так вот просто))) да!
    if user_input.lower() in ['exit', 'q', 'выход']:
        fileL.close() ## Закрываем текстовик
        db.close() ## Закрываем базу данных
        break
    
    if not user_input or not user_input.strip(): ##Если юзер ничего не ввел.
     continue
    
    memorybank.append({"role": "user", "content": user_input}) ##Тут кароче контекст переписки хранится в мемерибанке, а этот словарь нужен что бы передовать модели контекст

    log(user_input, "user")
    
    
    try:

        relevant_past = search_memory(user_input)
        current_time = datetime.now().strftime("%d.%m.%Y %H:%M:%S")
        

        if len(memorybank) > 11:
            memorybank = [memorybank[0]] + memorybank[-10:] ##Если сообщений больше 10, то оставляем только последние 10 + системное сообщение, что бы не перегружать модель, а то там выйдет не пик-ми-герл, а татаро-ман-герл

        messages_to_send = [
            {"role": "system", "content": sys_prompt},
            {"role": "system", "content": f"Время: {current_time}. Твои старые записи по теме:\n{relevant_past}\nПоследние логи:\n{db_history}"}
        ] + memorybank[1:] ##Тут кароче мы добавляем в начало контекста текущее время, что бы модель не путалась во времени, а то она может забыть что сейчас день, а не ночь, или наоборот. И будт ночная татаро-ман-герл)))


        completion = client.chat.completions.create(
            model = neyromodels.GEMMA, ##Тут вибираем мдель, у меня их 2, но 2-я получше, ну мне так кажется
            messages = messages_to_send, ##тут кароче передаем модели контекст из меморибанка + вопрос юзера, да
            temperature=0.7, ##Это кароче настройка ее креативности, чем выше тем более креативные ответы, но это не всегда хорошо))), пс 0.8+ постаянно вываливает китайский язык, даже когда я ей запретил.
            max_tokens=300, ##Определяет размер текста, к сожалению даже на моей видюхе она со временем сходит с ума
            extra_body={
                "stop": ["<|im_end|>", "Вы:", "user:"], ##Это кароче что бы не писала системную часть в ответе, а оставляла только ответ. 
            }
        )

        print(f"\nБот: {completion.choices[0].message.content}\n")
        memorybank.append({"role": "assistant", "content": completion.choices[0].message.content}) ##Тут кароче добавляем ответ модели в контекст переписки, что бы она не забывала о чем говорили раньше
    
        log(completion.choices[0].message.content, "assistant")
    
        luna.say(completion.choices[0].message.content) ##Тут кароче Луна озвучивает ответ модели


##херня ниже нужна что бы трай не спамил ошибкой в консоль, если что то пойдет не так, ну точнее что бы воводил ошибку красиво.
    except Exception as e:
        print(f"Ошибка: {e}")
db.commit()
db.close()